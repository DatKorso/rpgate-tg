"""Memory Manager Agent - Campaign Historian.

–ê–≥–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ long-term –ø–∞–º—è—Ç–∏.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç RAG (Retrieval-Augmented Generation) –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π.
"""

from typing import Any, List, Optional
from uuid import UUID
import logging

from app.agents.base import BaseAgent
from app.config.models import AGENT_CONFIGS
from app.memory.episodic import episodic_memory_manager
from app.db.models import EpisodicMemoryDB

logger = logging.getLogger(__name__)


class MemoryManagerAgent(BaseAgent):
    """
    Agent –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é –∏ retrieval.
    
    –†–æ–ª—å: "Campaign Historian"
    –ó–∞–¥–∞—á–∞: –ò–∑–≤–ª–µ—á—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ long-term –ø–∞–º—è—Ç–∏
    
    Workflow:
    1. Vector search –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
    2. Temporal retrieval –¥–ª—è –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π
    3. Importance filtering –¥–ª—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞ –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–∞—Ö
    4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ summary –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    """
    
    def __init__(self):
        """Initialize Memory Manager Agent.
        
        Note: –≠—Ç–æ—Ç –∞–≥–µ–Ω—Ç –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã,
        —Ç–æ–ª—å–∫–æ embeddings + database queries.
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, –Ω–æ LLM –Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è retrieval
        super().__init__(
            name="MemoryManager",
            model_config=AGENT_CONFIGS.MEMORY_MANAGER,
        )
        self.top_k_default = 3  # Default –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö memories
        self.recent_limit_default = 5  # Default –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–¥–∞–≤–Ω–∏—Ö memories
        self.min_importance_default = 3  # –¢–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (3-10)
    
    async def execute(self, context: dict[str, Any]) -> dict[str, Any]:
        """
        Retrieve relevant memories for current action.
        
        Args:
            context: {
                "user_action": str - –î–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞
                "character_id": UUID - ID –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ DB
                "session_id": UUID (optional) - ID —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
                "top_k": int (optional) - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö memories (default 3)
                "recent_limit": int (optional) - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–¥–∞–≤–Ω–∏—Ö memories (default 5)
                "min_importance": int (optional) - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å (default 3)
            }
            
        Returns:
            {
                "relevant_memories": List[tuple[EpisodicMemoryDB, float]] - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏–µ
                "recent_memories": List[EpisodicMemoryDB] - –ù–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
                "memory_summary": str - –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
                "total_found": int - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö memories
            }
        """
        try:
            # Extract parameters
            user_action = context["user_action"]
            character_id: UUID = context["character_id"]
            session_id: Optional[UUID] = context.get("session_id")
            top_k = context.get("top_k", self.top_k_default)
            recent_limit = context.get("recent_limit", self.recent_limit_default)
            min_importance = context.get("min_importance", self.min_importance_default)
            
            self.logger.info(
                f"Memory retrieval for character {character_id}: '{user_action[:50]}...'"
            )
            
            # Step 1: Vector search –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö memories
            relevant_memories = await episodic_memory_manager.search_memories(
                character_id=character_id,
                query=user_action,
                limit=top_k,
                similarity_threshold=0.5,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è similarity –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
                min_importance=min_importance
            )
            
            self.logger.info(
                f"Found {len(relevant_memories)} relevant memories "
                f"(threshold=0.5, min_importance={min_importance})"
            )
            
            # Step 2: Get recent memories –¥–ª—è immediate context
            recent_memories = await episodic_memory_manager.get_recent_memories(
                character_id=character_id,
                limit=recent_limit,
                session_id=session_id  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–µ–π
            )
            
            self.logger.info(
                f"Retrieved {len(recent_memories)} recent memories "
                f"(session_id={session_id})"
            )
            
            # Step 3: Build memory summary –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            memory_summary = self._build_memory_summary(
                relevant_memories,
                recent_memories
            )
            
            output = {
                "relevant_memories": relevant_memories,
                "recent_memories": recent_memories,
                "memory_summary": memory_summary,
                "total_found": len(relevant_memories) + len(recent_memories)
            }
            
            self.log_execution(context, output)
            return output
            
        except Exception as e:
            self.logger.error(f"Memory retrieval failed: {e}", exc_info=True)
            # Return empty result on error
            return {
                "relevant_memories": [],
                "recent_memories": [],
                "memory_summary": "‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π.",
                "total_found": 0
            }
    
    def _build_memory_summary(
        self,
        relevant: List[tuple[EpisodicMemoryDB, float]],
        recent: List[EpisodicMemoryDB]
    ) -> str:
        """
        Build —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –ø–∞–º—è—Ç–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
        
        Args:
            relevant: List of (memory, similarity_score) tuples
            recent: List of recent memories
            
        Returns:
            Formatted string –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ LLM prompt
        """
        parts = []
        
        # Relevant memories section (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏–µ)
        if relevant:
            parts.append("üìö **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è:**")
            for memory, similarity in relevant[:3]:  # Top 3
                # Importance stars (‚≠ê x score)
                importance_stars = "‚≠ê" * min(memory.importance_score, 5)
                
                # Similarity percentage
                similarity_pct = int(similarity * 100)
                
                # Format: content (similarity%, importance)
                parts.append(
                    f"- {memory.content} "
                    f"({similarity_pct}% –ø–æ—Ö–æ–∂–µ, {importance_stars})"
                )
        
        # Recent memories section (–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
        if recent:
            parts.append("\nüìÖ **–ù–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è:**")
            for memory in recent[:3]:  # Last 3
                # Location tag if available
                location_tag = f"[{memory.location}]" if memory.location else ""
                
                parts.append(f"- {memory.content} {location_tag}")
        
        # Empty state
        if not parts:
            return "üí≠ –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π (–Ω–æ–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂)."
        
        return "\n".join(parts)
    
    async def extract_memory_metadata(
        self,
        user_action: str,
        assistant_response: str,
        mechanics_result: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract metadata for memory creation (–±–µ–∑ LLM, rule-based).
        
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç:
        - memory_type (event, dialogue, discovery, combat)
        - importance_score (0-10)
        - entities (extracted keywords)
        - location (from context)
        
        Args:
            user_action: –î–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞
            assistant_response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            mechanics_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Rules Arbiter
            
        Returns:
            {
                "memory_type": str,
                "importance_score": int,
                "entities": List[str],
                "suggested_location": str
            }
        """
        # Determine memory type based on mechanics
        action_type = mechanics_result.get("action_type", "other")
        
        type_mapping = {
            "attack": "combat",
            "spell": "combat",
            "skill_check": "event",
            "other": "event"
        }
        
        memory_type = type_mapping.get(action_type, "event")
        
        # Check for dialogue keywords (–≤ user_action –ò–õ–ò assistant_response)
        dialogue_keywords = ["–≥–æ–≤–æ—Ä", "—Å–ø—Ä–æ—Å", "–æ—Ç–≤–µ—Ç", "—Å–∫–∞–∑–∞–ª", "–ø—Ä–æ–∏–∑–Ω—ë—Å", "–¥–∏–∞–ª–æ–≥", "—Å–ø—Ä–∞—à–∏–≤–∞"]
        combined_text = (user_action + " " + assistant_response).lower()
        if any(keyword in combined_text for keyword in dialogue_keywords):
            memory_type = "dialogue"
        
        # Check for discovery keywords
        discovery_keywords = ["–Ω–∞—Ö–æ–¥–∏—Ç", "–æ–±–Ω–∞—Ä—É–∂–∏–ª", "–Ω–∞—à—ë–ª", "–æ—Ç–∫—Ä—ã–ª", "—É–∑–Ω–∞–ª"]
        if any(keyword in assistant_response.lower() for keyword in discovery_keywords):
            memory_type = "discovery"
        
        # Determine importance (simple heuristic)
        importance_score = 5  # Default
        
        # Discoveries are important
        if memory_type == "discovery":
            importance_score = 7
        
        # Combat events are medium importance
        if memory_type == "combat":
            importance_score = 6
        
        # Critical events = higher importance (override combat default)
        if mechanics_result.get("success") and action_type == "attack":
            if mechanics_result.get("mechanics_result", {}).get("is_critical"):
                importance_score = 8  # Critical hit!
        
        # Extract entities (simple keyword extraction)
        # TODO: –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å NER (Named Entity Recognition)
        entities = self._extract_entities(user_action + " " + assistant_response)
        
        return {
            "memory_type": memory_type,
            "importance_score": importance_score,
            "entities": entities,
            "suggested_location": None  # Will be set from character state
        }
    
    def _extract_entities(self, text: str) -> List[str]:
        """
        Simple entity extraction from text (rule-based).
        
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç:
        - –°—É—â–µ—Å—Ç–≤–∞ (–≥–æ–±–ª–∏–Ω, –≤–æ–ª–∫, –¥—Ä–∞–∫–æ–Ω, –∏ —Ç.–¥.)
        - –õ–æ–∫–∞—Ü–∏–∏ (–ø–µ—â–µ—Ä–∞, —Ç–∞–≤–µ—Ä–Ω–∞, –ª–µ—Å, –∏ —Ç.–¥.)
        - –ü—Ä–µ–¥–º–µ—Ç—ã (–º–µ—á, –∑–µ–ª—å–µ, –∞–º—É–ª–µ—Ç, –∏ —Ç.–¥.)
        
        Args:
            text: Input text
            
        Returns:
            List of extracted entities
        """
        # Common fantasy entities (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        entity_patterns = {
            # Creatures
            "–≥–æ–±–ª–∏–Ω", "–æ—Ä–∫", "–¥—Ä–∞–∫–æ–Ω", "–≤–æ–ª–∫", "–º–µ–¥–≤–µ–¥—å", "—Ç—Ä–æ–ª–ª—å",
            "—ç–ª—å—Ñ", "–¥–≤–∞—Ä—Ñ", "—á–µ–ª–æ–≤–µ–∫", "–º–∞–≥", "–≤–æ–∏–Ω", "—Ä–∞–∑–±–æ–π–Ω–∏–∫",
            "–±–∞—Ä–º–µ–Ω",  # NPCs
            
            # Locations
            "–ø–µ—â–µ—Ä", "—Ç–∞–≤–µ—Ä–Ω", "–ª–µ—Å", "–≥–æ—Ä–æ–¥", "–¥–µ—Ä–µ–≤–Ω", "–∑–∞–º–æ–∫",
            "—Ö—Ä–∞–º", "–ø–æ–¥–∑–µ–º–µ–ª—å", "—Ä—É–¥–Ω–∏–∫", "–±–æ–ª–æ—Ç",
            
            # Items
            "–º–µ—á", "—Ç–æ–ø–æ—Ä", "–ª—É–∫", "–∫–∏–Ω–∂–∞–ª", "–∑–µ–ª—å–µ", "–∞–º—É–ª–µ—Ç",
            "—â–∏—Ç", "–±—Ä–æ–Ω", "–∫–æ–ª—å—Ü–æ", "—Å–≤–∏—Ç–æ–∫",
        }
        
        text_lower = text.lower()
        found_entities = []
        
        for entity in entity_patterns:
            if entity in text_lower:
                found_entities.append(entity)
        
        return list(set(found_entities))  # Remove duplicates


# Global instance
memory_manager_agent = MemoryManagerAgent()
